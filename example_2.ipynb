{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53175b1",
   "metadata": {},
   "source": [
    "# Try python-git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dea7218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 17:29:20,342 - DEBUG - sys.platform='linux', git_executable='git'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<git.repo.base.Repo '/home/haianhlt/Documents/bioturing/bioalpha/.git'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from git import Repo\n",
    "\n",
    "repo = Repo(\"/home/haianhlt/Documents/bioturing/bioalpha\")\n",
    "repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17559d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 17:29:20,378 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2026-02-02 17:29:20,383 - DEBUG - Popen(['git', 'merge-base', '36223441c04ac7033262998187508e1069c42733', '3e9fa5f0137544480673546b5ee1335d242abe7e'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=None, shell=False, universal_newlines=False)\n",
      "2026-02-02 17:29:20,391 - DEBUG - Popen(['git', 'diff-tree', '3e9fa5f0137544480673546b5ee1335d242abe7e', '36223441c04ac7033262998187508e1069c42733', '-r', '--abbrev=40', '--full-index', '-M', '-p', '--no-ext-diff', '--no-color'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=None, shell=False, universal_newlines=False)\n"
     ]
    }
   ],
   "source": [
    "target = repo.commit(\"tk726_zarr3\")\n",
    "base = repo.commit(\"main\")\n",
    "\n",
    "mutual_base = repo.merge_base(target, base)[0]\n",
    "diffs = mutual_base.diff(target, create_patch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca71ef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM src/bioalpha/_version.py TO src/bioalpha/_version.py \n",
      " @@ -28,7 +28,7 @@ version_tuple: VERSION_TUPLE\n",
      " commit_id: COMMIT_ID\n",
      " __commit_id__: COMMIT_ID\n",
      " \n",
      "-__version__ = version = '0.14.3.dev637+g37b41c149.d20250923'\n",
      "-__version_tuple__ = version_tuple = (0, 14, 3, 'dev637', 'g37b41c149.d20250923')\n",
      "+__version__ = version = '0.14.3.dev677+gb337a057a.d20260121'\n",
      "+__version_tuple__ = version_tuple = (0, 14, 3, 'dev677', 'gb337a057a.d20260121')\n",
      " \n",
      "-__commit_id__ = commit_id = 'g37b41c149'\n",
      "+__commit_id__ = commit_id = 'gb337a057a'\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff = diffs[0]\n",
    "print(f\"FROM {diff.a_path} TO {diff.b_path} \\n {diff.diff.decode('utf-8')} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cd03c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM src/bioalpha/store/anndata/__init__.py TO src/bioalpha/store/anndata/__init__.py \n",
      " @@ -25,12 +25,11 @@ from bioalpha.store.anndata.shared import SharedObs, SharedUns, SharedObsm, Shar\n",
      " from bioalpha.constants import IOSpecs, AnnDataAttr, AnnDataAxis, AnnDataViewAttr\n",
      " from bioalpha.utils import (\n",
      "     validate_type,\n",
      "-    get_group_path,\n",
      "     is_group_readonly,\n",
      "     validate_subset_indices,\n",
      "     write_iospec,\n",
      " )\n",
      "-\n",
      "+from bioalpha.compat import get_group_path\n",
      " \n",
      " class BackedRaw:\n",
      "     \"\"\"Currently support read-only\"\"\"\n",
      "@@ -678,7 +677,7 @@ class SharedAssay(Assay):\n",
      "         if not public_read_only:\n",
      "             group = zarr.group(public_path)\n",
      "         else:\n",
      "-            group = zarr.Group(public_path, read_only=public_read_only)\n",
      "+            group = zarr.open_group(public_path, mode = \"r\")\n",
      "         super().__init__(group=group, ref=ref)\n",
      "         self.private = Assay(zarr.open(private_path), ref=ref)\n",
      "         if len(self.private.var_names) == 0:\n",
      "@@ -757,7 +756,7 @@ class SharedAnnData(AppAnnData):\n",
      "         if not public_read_only:\n",
      "             group = zarr.group(public_path)\n",
      "         else:\n",
      "-            group = zarr.Group(public_path, read_only=public_read_only)\n",
      "+            group = zarr.open_group(public_path, mode='r')\n",
      "         super().__init__(group)\n",
      "         self.private = AppAnnData(zarr.open(private_path))\n",
      "         if standardize_path:\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff = diffs[5]\n",
    "print(f\"FROM {diff.a_path} TO {diff.b_path} \\n {diff.diff.decode('utf-8')} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "870a8fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 17:29:20,429 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from . import _io_register as _\n",
      "\n",
      "import uuid\n",
      "import zarr\n",
      "import h5py\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import sparse\n",
      "from functools import cached_property\n",
      "from typing import Optional, Any, Union, Tuple, List, Iterator, Iterable\n",
      "\n",
      "from anndata import AnnData\n",
      "from anndata.utils import make_index_unique\n",
      "from anndata._io.specs import write_elem, read_elem\n",
      "\n",
      "from bioalpha.store._basic import AppCollection\n",
      "from bioalpha.store.matrix import CSCMatrix, CSRMatrix, SpMatrixView, CSCCollection\n",
      "from bioalpha.store.dataframe import BackedObs, BackedVar, AppObs, AppVar, DataFrameView\n",
      "from bioalpha.store.anndata.container import (\n",
      "    BackedObsm, BackedVarm, BackedObsp, BackedVarp, BackedLayers, BackedUns,\n",
      "    AppObsm, AppVarm, AppObsp, AppVarp, AppLayers, AppUns, ContainerView,\n",
      ")\n",
      "from bioalpha.store.anndata.shared import SharedObs, SharedUns, SharedObsm, SharedVarm, SharedVar\n",
      "\n",
      "from bioalpha.constants import IOSpecs, AnnDataAttr, AnnDataAxis, AnnDataViewAttr\n",
      "from bioalpha.utils import (\n",
      "    validate_type,\n",
      "    get_group_path,\n",
      "    is_group_readonly,\n",
      "    validate_subset_indices,\n",
      "    write_iospec,\n",
      ")\n",
      "\n",
      "\n",
      "class BackedRaw:\n",
      "    \"\"\"Currently support read-only\"\"\"\n",
      "    _group: Union[zarr.Group, h5py.File, h5py.Group] = None\n",
      "    _parent = None\n",
      "\n",
      "    def __init__(self, group: Union[zarr.Group, h5py.File, h5py.Group], parent):\n",
      "        self.group = group\n",
      "        self.parent = parent\n",
      "\n",
      "    @property\n",
      "    def _parent_cls(self):\n",
      "        return BackedAnnData\n",
      "\n",
      "    @property\n",
      "    def _var_cls(self):\n",
      "        return BackedVar\n",
      "\n",
      "    def _validate_parent(self, parent):\n",
      "        return validate_type(parent, self._parent_cls)\n",
      "\n",
      "    @property\n",
      "    def group(self):\n",
      "        return self._group\n",
      "\n",
      "    @group.setter\n",
      "    def group(self, group: zarr.Group):\n",
      "        validate_type(group, zarr.Group, h5py.File, h5py.Group)\n",
      "        self._group = group\n",
      "\n",
      "    @property\n",
      "    def parent(self):\n",
      "        return self._parent\n",
      "\n",
      "    @parent.setter\n",
      "    def parent(self, parent):\n",
      "        self._validate_parent(parent)\n",
      "        self._parent = parent\n",
      "\n",
      "    @cached_property\n",
      "    def X(self) -> Union[CSCMatrix, CSRMatrix]:\n",
      "        if AnnDataAttr.X.value in self.group:\n",
      "            return read_elem(self.group[AnnDataAttr.X.value])\n",
      "        return None\n",
      "\n",
      "    @cached_property\n",
      "    def var(self) -> BackedVar:\n",
      "        if AnnDataAttr.VAR.value in self.group:\n",
      "            return self._var_cls(self.group[AnnDataAttr.VAR.value], self)\n",
      "        return None\n",
      "\n",
      "    @cached_property\n",
      "    def var_names(self) -> pd.Index:\n",
      "        if self.var is not None:\n",
      "            return self.var.index\n",
      "        return None\n",
      "\n",
      "\n",
      "class AppRaw(BackedRaw):\n",
      "    @property\n",
      "    def _var_cls(self):\n",
      "        return AppVar\n",
      "\n",
      "\n",
      "class BackedAnnData(AnnData):\n",
      "    \"\"\"Container class for Anndata-like object.\"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        group: Union[zarr.Group, h5py.File, h5py.Group],\n",
      "        *,\n",
      "        X: Optional[Union[sparse.csc_matrix, np.ndarray]] = None,\n",
      "        obs_names: Iterator[Union[str, np.number]] = None,\n",
      "        var_names: Iterator[Union[str, np.number]] = None,\n",
      "    ):\n",
      "        self.group = group\n",
      "\n",
      "        if obs_names is not None:\n",
      "            self.obs.index = obs_names\n",
      "\n",
      "        if var_names is not None:\n",
      "            self.var.index = var_names\n",
      "\n",
      "        if X is not None:\n",
      "            if AnnDataAttr.X.value in self.group:\n",
      "                raise FileExistsError(\"X is already exists in Zarr Group\")\n",
      "            self.set_X(X)\n",
      "\n",
      "    def create_X(self, matrix_cls: type, overwrite: bool = False):\n",
      "        g = self.group.create_group(AnnDataAttr.X.value, overwrite=overwrite)\n",
      "        return matrix_cls(g, shape=self.shape)\n",
      "\n",
      "    @property\n",
      "    def is_view(self):\n",
      "        return False\n",
      "\n",
      "    @property\n",
      "    def group(self) -> zarr.Group:\n",
      "        return self._group\n",
      "\n",
      "    @group.setter\n",
      "    def group(self, group: zarr.Group):\n",
      "        validate_type(group, zarr.Group, h5py.File, h5py.Group)\n",
      "        self._group = group\n",
      "\n",
      "    @property\n",
      "    def group_path(self) -> zarr.Group:\n",
      "        return get_group_path(self.group)\n",
      "\n",
      "    def set_X(self, X: Union[sparse.csc_matrix, sparse.csr_matrix, SpMatrixView]):\n",
      "        if self.obs is not None:\n",
      "            assert X.shape[0] == len(self.obs)\n",
      "        if self.var is not None:\n",
      "            assert X.shape[1] == len(self.var)\n",
      "        write_elem(self.group, AnnDataAttr.X.value, X)\n",
      "\n",
      "    @property\n",
      "    def _obs_cls(self):\n",
      "        return BackedObs\n",
      "\n",
      "    @property\n",
      "    def _var_cls(self):\n",
      "        return BackedVar\n",
      "\n",
      "    @property\n",
      "    def _obsm_cls(self):\n",
      "        return BackedObsm\n",
      "\n",
      "    @property\n",
      "    def _varm_cls(self):\n",
      "        return BackedVarm\n",
      "\n",
      "    @property\n",
      "    def _obsp_cls(self):\n",
      "        return BackedObsp\n",
      "\n",
      "    @property\n",
      "    def _varp_cls(self):\n",
      "        return BackedVarp\n",
      "\n",
      "    @property\n",
      "    def _layers_cls(self):\n",
      "        return BackedLayers\n",
      "\n",
      "    @property\n",
      "    def _uns_cls(self):\n",
      "        return BackedUns\n",
      "\n",
      "    @property\n",
      "    def _raw_cls(self):\n",
      "        return BackedRaw\n",
      "\n",
      "    def _init_attribute(self, key: str, Attribute, *, ref: Optional[\"BackedAnnData\"] = None):\n",
      "        ref = self if ref is None else ref\n",
      "        if key not in self.group:\n",
      "            if is_group_readonly(self.group):  # HDF5 readonly\n",
      "                return None\n",
      "            self.group.create_group(key)\n",
      "        return Attribute(self.group[key], ref)\n",
      "\n",
      "    @cached_property\n",
      "    def X(self) -> Union[CSCMatrix, CSRMatrix]:\n",
      "        if AnnDataAttr.X.value in self.group:\n",
      "            return read_elem(self.group[AnnDataAttr.X.value])\n",
      "        return None\n",
      "\n",
      "    @cached_property\n",
      "    def obs(self) -> BackedObs:\n",
      "        return self._init_attribute(AnnDataAttr.OBS.value, self._obs_cls)\n",
      "\n",
      "    @cached_property\n",
      "    def var(self) -> BackedVar:\n",
      "        return self._init_attribute(AnnDataAttr.VAR.value, self._var_cls)\n",
      "\n",
      "    @cached_property\n",
      "    def obsm(self) -> BackedObsm:\n",
      "        return self._init_attribute(AnnDataAttr.OBSM.value, self._obsm_cls)\n",
      "\n",
      "    @cached_property\n",
      "    def varm(self) -> BackedVarm:\n",
      "        return self._init_attribute(AnnDataAttr.VARM.value, self._varm_cls)\n",
      "\n",
      "    @cached_property\n",
      "    def obsp(self) -> BackedObsp:\n",
      "        return self._init_attribute(AnnDataAttr.OBSP.value, self._obsp_cls)\n",
      "\n",
      "    @cached_property\n",
      "    def varp(self) -> BackedVarp:\n",
      "        return self._init_attribute(AnnDataAttr.VARP.value, self._varp_cls)\n",
      "\n",
      "    @cached_property\n",
      "    def layers(self) -> BackedLayers:\n",
      "        return self._init_attribute(AnnDataAttr.LAYERS.value, self._layers_cls)\n",
      "\n",
      "    @cached_property\n",
      "    def uns(self) -> BackedUns:\n",
      "        return self._init_attribute(AnnDataAttr.UNS.value, self._uns_cls)\n",
      "\n",
      "    @cached_property\n",
      "    def raw(self) -> BackedRaw:\n",
      "        if AnnDataAttr.RAW.value in self.group:\n",
      "            return self._raw_cls(self.group[AnnDataAttr.RAW.value], self)\n",
      "        return None\n",
      "\n",
      "    @property\n",
      "    def n_obs(self):\n",
      "        return len(self.obs) if self.obs else None\n",
      "\n",
      "    @property\n",
      "    def n_vars(self):\n",
      "        return len(self.var) if self.var else None\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        descr = (\n",
      "            f\"{type(self).__name__} object with \"\n",
      "            f\"n_obs × n_vars = {self.n_obs} × {self.n_vars}\"\n",
      "        )\n",
      "        for attr in AnnDataAttr:\n",
      "            if attr.value not in self.group:\n",
      "                continue\n",
      "            if attr == AnnDataAttr.X:\n",
      "                continue\n",
      "            keys = getattr(self, attr.value).keys()\n",
      "            if len(keys) > 0:\n",
      "                descr += f\"\\n    {attr.value}: {str(list(keys))[1:-1]}\"\n",
      "        return descr\n",
      "\n",
      "    def __eq__(self, other):\n",
      "        super(AnnData, self).__eq__(other)\n",
      "\n",
      "    def __write_attrs(self, f, key, dataset_kwargs):\n",
      "        try:\n",
      "            write_elem(f, key, dict(getattr(self, key)), dataset_kwargs=dataset_kwargs)\n",
      "        except Exception:\n",
      "            write_elem(f, key, {}, dataset_kwargs=dataset_kwargs)\n",
      "\n",
      "    def __write_obs(self, f, *, dataset_kwargs={}):\n",
      "        # Directly use to_df cause issues when the case the .zmetadata bug\n",
      "        # (2 workers saving at the same time)\n",
      "        data = {}\n",
      "        for col in self.obs.columns:\n",
      "            try:\n",
      "                data[col] = self.obs[col]\n",
      "            except Exception:  # pylint: disable=broad-except\n",
      "                continue\n",
      "        df = pd.DataFrame(index=self.obs_names, data=data)\n",
      "        write_elem(f, \"obs\", df, dataset_kwargs=dataset_kwargs)\n",
      "\n",
      "    def __write_group(self, f, *, dataset_kwargs={}):\n",
      "        f.attrs.setdefault(\"encoding-type\", \"anndata\")\n",
      "        f.attrs.setdefault(\"encoding-version\", \"0.1.0\")\n",
      "        if self.raw is not None:\n",
      "            write_elem(f, \"raw\", self.raw, dataset_kwargs=dataset_kwargs)\n",
      "        write_elem(f, \"X\", self.X, dataset_kwargs=dataset_kwargs)\n",
      "        self.__write_obs(f, dataset_kwargs=dataset_kwargs)\n",
      "        write_elem(f, \"var\", self.var.to_df(), dataset_kwargs=dataset_kwargs)\n",
      "        write_elem(f, \"obsm\", self.obsm, dataset_kwargs=dataset_kwargs)\n",
      "        write_elem(f, \"layers\", self.layers, dataset_kwargs=dataset_kwargs)\n",
      "        self.__write_attrs(f, \"varm\", dataset_kwargs)\n",
      "        self.__write_attrs(f, \"obsp\", dataset_kwargs)\n",
      "        self.__write_attrs(f, \"varp\", dataset_kwargs)\n",
      "        write_elem(f, \"uns\", {}, dataset_kwargs=dataset_kwargs)\n",
      "\n",
      "    def write_h5ad(self, filepath, *, dataset_kwargs={}):\n",
      "        with h5py.File(filepath, \"w\") as f:\n",
      "            f = f[\"/\"]\n",
      "            self.__write_group(f, dataset_kwargs=dataset_kwargs)\n",
      "\n",
      "    def __get_mod(self, mod: str):\n",
      "        return self if mod == \"RNA\" else self.assays[mod]\n",
      "\n",
      "    def __write_mapper(self, file, attr: str, assays_list: List[str], kwargs):\n",
      "        dfs = []\n",
      "        for assay in assays_list:\n",
      "            names = getattr(self.__get_mod(assay), attr).index.values\n",
      "            dfs.append(\n",
      "                pd.DataFrame(index=names, data={assay: np.arange(1, len(names) + 1)})\n",
      "            )\n",
      "        dfs = pd.concat(dfs, axis=1).fillna(0)\n",
      "        mapper = {x: dfs[x].astype(int).values for x in assays_list}\n",
      "        write_elem(file, attr, dfs[[]], dataset_kwargs=kwargs)\n",
      "        write_elem(file, f\"{attr}map\", mapper, dataset_kwargs=kwargs)\n",
      "\n",
      "    def write_h5mu(self, filepath, **kwargs):\n",
      "        import mudata\n",
      "        with h5py.File(filepath, \"w\") as file:\n",
      "            file = file[\"/\"]\n",
      "            assay_list = [\"RNA\", *list(self.assays.keys())]\n",
      "            self.__write_mapper(file, \"obs\", assay_list, kwargs)\n",
      "            self.__write_mapper(file, \"var\", assay_list, kwargs)\n",
      "\n",
      "            attrs = file.attrs\n",
      "            attrs[\"axis\"] = 0\n",
      "\n",
      "            mod = file.require_group(\"mod\")\n",
      "            for k in assay_list:\n",
      "                group = mod.require_group(k)\n",
      "                adata = self.__get_mod(k)\n",
      "                adata.__write_group(group, dataset_kwargs=kwargs)\n",
      "                attrs = group.attrs\n",
      "                attrs[\"encoder\"] = \"mudata\"\n",
      "                attrs[\"encoder-version\"] = mudata.__version__\n",
      "\n",
      "            mod_attrs = mod.attrs\n",
      "            mod_attrs[\"mod-order\"] = assay_list\n",
      "\n",
      "            attrs = file.attrs\n",
      "            attrs[\"encoding-type\"] = \"MuData\"\n",
      "            attrs[\"encoding-version\"] = mudata.__mudataversion__\n",
      "            attrs[\"encoder\"] = \"mudata\"\n",
      "            attrs[\"encoder-version\"] = mudata.__version__\n",
      "\n",
      "\n",
      "class AppAnnData(BackedAnnData):\n",
      "    @property\n",
      "    def _obs_cls(self):\n",
      "        return AppObs\n",
      "\n",
      "    @property\n",
      "    def _var_cls(self):\n",
      "        return AppVar\n",
      "\n",
      "    @property\n",
      "    def _obsm_cls(self):\n",
      "        return AppObsm\n",
      "\n",
      "    @property\n",
      "    def _varm_cls(self):\n",
      "        return AppVarm\n",
      "\n",
      "    @property\n",
      "    def _obsp_cls(self):\n",
      "        return AppObsp\n",
      "\n",
      "    @property\n",
      "    def _varp_cls(self):\n",
      "        return AppVarp\n",
      "\n",
      "    @property\n",
      "    def _layers_cls(self):\n",
      "        return AppLayers\n",
      "\n",
      "    @property\n",
      "    def _uns_cls(self):\n",
      "        return AppUns\n",
      "\n",
      "    @property\n",
      "    def _raw_cls(self):\n",
      "        return AppRaw\n",
      "\n",
      "    @cached_property\n",
      "    def subclusters(self):\n",
      "        return self._init_attribute(AnnDataAttr.SUBCLUSTERS.value, SubClusters)\n",
      "\n",
      "    @cached_property\n",
      "    def assays(self):\n",
      "        return self._init_attribute(AnnDataAttr.ASSAYS.value, Assays)\n",
      "\n",
      "\n",
      "class AnnDataView(AppAnnData):\n",
      "    def __init__(\n",
      "        self,\n",
      "        group: zarr.Group,\n",
      "        ref: AppAnnData,\n",
      "        *,\n",
      "        indices: Tuple[Optional[np.ndarray], Optional[np.ndarray]] = None,\n",
      "    ):\n",
      "        self._ref = ref\n",
      "        self.group = group\n",
      "\n",
      "        if not is_group_readonly(group):\n",
      "            write_iospec(IOSpecs.SUBCLUSTER.value, group, overwrite=False)\n",
      "\n",
      "        if indices is not None:\n",
      "            self.init_indices(indices)\n",
      "\n",
      "    @property\n",
      "    def n_obs(self):\n",
      "        obs_indices = self.indices[AnnDataAxis.OBS.value]\n",
      "        return self.ref.n_obs if obs_indices is None else len(obs_indices)\n",
      "\n",
      "    @property\n",
      "    def n_vars(self):\n",
      "        vars_indices = self.indices[AnnDataAxis.VAR.value]\n",
      "        return self.ref.n_vars if vars_indices is None else len(vars_indices)\n",
      "\n",
      "    @property\n",
      "    def ref(self):\n",
      "        return self._ref\n",
      "\n",
      "    @cached_property\n",
      "    def indices(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:\n",
      "        obs_indices = read_elem(self.group[AnnDataViewAttr.OBS_INDICES.value]) \\\n",
      "            if AnnDataViewAttr.OBS_INDICES.value in self.group else None\n",
      "        var_indices = read_elem(self.group[AnnDataViewAttr.VAR_INDICES.value]) \\\n",
      "            if AnnDataViewAttr.VAR_INDICES.value in self.group else None\n",
      "        return (obs_indices, var_indices)\n",
      "\n",
      "    def init_indices(self, indices: Tuple[Optional[np.ndarray], Optional[np.ndarray]]):\n",
      "        if indices[AnnDataAxis.OBS.value] is not None:\n",
      "            validate_subset_indices(indices[AnnDataAxis.OBS.value], self.ref.n_obs)\n",
      "            write_elem(self.group, AnnDataViewAttr.OBS_INDICES.value,\n",
      "                       indices[AnnDataAxis.OBS.value])\n",
      "        if indices[AnnDataAxis.VAR.value] is not None:\n",
      "            validate_subset_indices(indices[AnnDataAxis.VAR.value], self.ref.n_vars)\n",
      "            write_elem(self.group, AnnDataViewAttr.VAR_INDICES.value,\n",
      "                       indices[AnnDataAxis.VAR.value])\n",
      "\n",
      "    @cached_property\n",
      "    def X(self) -> SpMatrixView:\n",
      "        return SpMatrixView(self.ref.X, self.indices)\n",
      "\n",
      "    @cached_property\n",
      "    def obs(self) -> DataFrameView:\n",
      "        return DataFrameView(self.ref.obs, self)\n",
      "\n",
      "    @cached_property\n",
      "    def var(self) -> DataFrameView:\n",
      "        return DataFrameView(self.ref.var, self)\n",
      "\n",
      "    @cached_property\n",
      "    def layers(self) -> ContainerView:\n",
      "        return ContainerView(self.ref.layers, self)\n",
      "\n",
      "    @cached_property\n",
      "    def assays(self):\n",
      "        return self.ref._init_attribute(AnnDataAttr.ASSAYS.value, Assays, ref=self)\n",
      "\n",
      "    @property\n",
      "    def subclusters(self):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    @property\n",
      "    def is_view(self):\n",
      "        return True\n",
      "\n",
      "\n",
      "class SubClusters(AppCollection):\n",
      "    def __init__(self, group: zarr.Group, parent) -> None:\n",
      "        self._group = group\n",
      "        self._parent = parent\n",
      "\n",
      "        if not is_group_readonly(group):\n",
      "            write_iospec(IOSpecs.BTR_DICT.value, group, overwrite=False)\n",
      "\n",
      "    @property\n",
      "    def parent(self):\n",
      "        return self._parent\n",
      "\n",
      "    @property\n",
      "    def group(self) -> zarr.Group:\n",
      "        return self._group\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.keys())\n",
      "\n",
      "    def _validate_value(self, values: Any):\n",
      "        pass\n",
      "\n",
      "    def _get_item_impl(self, key: str) -> pd.Series:\n",
      "        return AnnDataView(self.group[key], self.parent)\n",
      "\n",
      "    def _set_item_impl(self, key, values):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    def _del_item_impl(self, key: str):\n",
      "        if len(key) == 0:\n",
      "            raise KeyError(\"Unable to delete item with the empty key.\")\n",
      "        if key in self.group:\n",
      "            del self.group[key]\n",
      "\n",
      "    def create_subcluster(self, key: str, indices: Tuple[np.ndarray, np.ndarray]):\n",
      "        ret = AnnDataView(self.group.create_group(\n",
      "            key, overwrite=True), self.parent, indices=indices)\n",
      "        self._add_name(key, key)\n",
      "        return ret\n",
      "\n",
      "\n",
      "class Assay(AppAnnData):\n",
      "    def __init__(\n",
      "        self,\n",
      "        group: zarr.Group,\n",
      "        ref: Union[AppAnnData, AnnDataView],\n",
      "        X: Optional[Union[sparse.csc_matrix, np.ndarray]] = None,\n",
      "        var_names: Iterator[Union[str, np.number]] = None,\n",
      "    ):\n",
      "        self.ref = ref\n",
      "        self.group = group\n",
      "\n",
      "        if not is_group_readonly(group):\n",
      "            write_iospec(IOSpecs.ASSAY.value, group, overwrite=False)\n",
      "\n",
      "        if var_names is not None:\n",
      "            self.var.index = var_names\n",
      "\n",
      "        if X is not None:\n",
      "            if AnnDataAttr.X.value in self.group:\n",
      "                raise FileExistsError(\"X is already exists in Zarr Group\")\n",
      "            self.set_X(X)\n",
      "\n",
      "    @property\n",
      "    def ref(self):\n",
      "        return self._ref\n",
      "\n",
      "    @ref.setter\n",
      "    def ref(self, val: Union[AppAnnData, AnnDataView]):\n",
      "        if val.is_view and val.indices[AnnDataAxis.VAR.value] is not None:\n",
      "            raise RuntimeError(\"Var view on assays is not supported\")\n",
      "        self._ref = val\n",
      "\n",
      "    @property\n",
      "    def n_obs(self):\n",
      "        return self.ref.n_obs\n",
      "\n",
      "    @cached_property\n",
      "    def obs(self) -> BackedObs:\n",
      "        return self.ref.obs\n",
      "\n",
      "    @cached_property\n",
      "    def obsm(self) -> BackedObsm:\n",
      "        return self.ref.obsm\n",
      "\n",
      "    @cached_property\n",
      "    def obsp(self) -> BackedObsp:\n",
      "        return self.ref.obsp\n",
      "\n",
      "    @cached_property\n",
      "    def uns(self) -> BackedUns:\n",
      "        return self.ref.uns\n",
      "\n",
      "    @cached_property\n",
      "    def X(self) -> SpMatrixView:\n",
      "        if AnnDataAttr.X.value in self.group:\n",
      "            ret = read_elem(self.group[AnnDataAttr.X.value])\n",
      "            return SpMatrixView(ret, self.ref.indices) if self.ref.is_view else ret\n",
      "        return None\n",
      "\n",
      "    @property\n",
      "    def subclusters(self):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    @property\n",
      "    def assays(self):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    @property\n",
      "    def is_view(self):\n",
      "        return self.ref.is_view\n",
      "\n",
      "    @property\n",
      "    def layers(self):\n",
      "        attr = super().layers\n",
      "        if self.is_view:\n",
      "            return ContainerView(attr, self.ref)\n",
      "        return attr\n",
      "\n",
      "\n",
      "class Assays(AppCollection):\n",
      "    def __init__(self, group: zarr.Group, parent) -> None:\n",
      "        self._group = group\n",
      "        self._parent = parent\n",
      "\n",
      "        if not is_group_readonly(group):\n",
      "            write_iospec(IOSpecs.BTR_DICT.value, group, overwrite=False)\n",
      "\n",
      "    @property\n",
      "    def parent(self):\n",
      "        return self._parent\n",
      "\n",
      "    @property\n",
      "    def group(self) -> zarr.Group:\n",
      "        return self._group\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.keys())\n",
      "\n",
      "    def _validate_value(self, values: Any):\n",
      "        pass\n",
      "\n",
      "    def _get_item_impl(self, key: str) -> pd.Series:\n",
      "        return Assay(self.group[key], self.parent)\n",
      "\n",
      "    def _set_item_impl(self, key, values):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    def _del_item_impl(self, key: str):\n",
      "        if len(key) == 0:\n",
      "            raise KeyError(\"Unable to delete item with the empty key.\")\n",
      "        if key in self.group:\n",
      "            del self.group[key]\n",
      "\n",
      "    def create_assay(self, key: str, var_names: List[str], X: Optional[Union[sparse.csc_matrix, np.ndarray]] = None):\n",
      "        elem_id = self.generate_elem_id()\n",
      "        group = self.group.create_group(elem_id, overwrite=True)\n",
      "        ret = Assay(group, self.parent, X=X, var_names=var_names)\n",
      "        old_uid = self._add_name(elem_id, key)\n",
      "        if old_uid is not None and old_uid in self.group:\n",
      "            del self.group[old_uid]\n",
      "        return ret\n",
      "\n",
      "\n",
      "def create_anndata_collection(\n",
      "    group: zarr.Group, refs: List[AppAnnData], *,\n",
      "    barcode_prefixes: Optional[List[str]] = None,\n",
      "):\n",
      "    if AnnDataAttr.X.value in group:\n",
      "        raise FileExistsError(\"X is already exists in Zarr Group\")\n",
      "\n",
      "    if barcode_prefixes is None:\n",
      "        obs_names = np.concatenate([adata.obs_names.values for adata in refs])\n",
      "    else:\n",
      "        assert len(barcode_prefixes) == len(refs), \\\n",
      "            \"Found mismatch length of prefix barcodes and reference anndata\"\n",
      "        obs_names = np.concatenate([\n",
      "            pd.Index([prefix] * adata.n_obs).astype(str).str.cat(adata.obs_names.values).values\n",
      "            for prefix, adata in zip(barcode_prefixes, refs)\n",
      "        ])\n",
      "    obs_names = pd.Index(obs_names, dtype=str)\n",
      "\n",
      "    if len(set(obs_names)) < len(obs_names):\n",
      "        obs_names = make_index_unique(obs_names, join=\"-btr-\")\n",
      "\n",
      "    var_names = np.concatenate([adata.var_names.values for adata in refs])\n",
      "    var_names = pd.Index(np.unique(var_names))\n",
      "\n",
      "    ref_indices = [pd.Index(adata.var_names).get_indexer(var_names) for adata in refs]\n",
      "    sparse_matrices = [adata.X for adata in refs]\n",
      "\n",
      "    return AppAnnData(\n",
      "        group,\n",
      "        X=CSCCollection(refs=sparse_matrices, ref_indices=ref_indices),\n",
      "        obs_names=obs_names, var_names=var_names,\n",
      "    )\n",
      "\n",
      "\n",
      "class SharedAssay(Assay):\n",
      "    def __init__(\n",
      "            self,\n",
      "            private_path: str,\n",
      "            public_path: str,\n",
      "            ref: \"SharedAnnData\",\n",
      "            var_names: Iterable[str],\n",
      "            public_read_only: bool = True\n",
      "    ):\n",
      "        if not public_read_only:\n",
      "            group = zarr.group(public_path)\n",
      "        else:\n",
      "            group = zarr.Group(public_path, read_only=public_read_only)\n",
      "        super().__init__(group=group, ref=ref)\n",
      "        self.private = Assay(zarr.open(private_path), ref=ref)\n",
      "        if len(self.private.var_names) == 0:\n",
      "            self.private = Assay(zarr.open(private_path), ref=ref, var_names=var_names)\n",
      "        self.ref = ref\n",
      "\n",
      "    def _init_private_attribute(self, key: str, SharedAttribute, Attribute):\n",
      "        if key not in self.private.group:\n",
      "            self.private.group.create_group(key)\n",
      "        return SharedAttribute(self.private.group[key], self, self._init_attribute(key, Attribute))\n",
      "\n",
      "    @cached_property\n",
      "    def var(self) -> SharedVar:\n",
      "        return self._init_private_attribute(AnnDataAttr.VAR.value, SharedVar, AppVar)\n",
      "\n",
      "    @cached_property\n",
      "    def varm(self) -> SharedVarm:\n",
      "        return self._init_private_attribute(AnnDataAttr.VARM.value, SharedVarm, AppVarm)\n",
      "\n",
      "\n",
      "class SharedAssays(Assays):\n",
      "    def __init__(self, zarr_group: zarr.Group, parent: \"SharedAnnData\", reference: Assays):\n",
      "        super().__init__(zarr_group, parent)\n",
      "        self.reference: Assays = reference\n",
      "        self._name2id = self.reference._name2id\n",
      "\n",
      "    def __contains__(self, key):\n",
      "        return super().__contains__(key) or self.reference.__contains__(key)\n",
      "\n",
      "    def _get_item_impl(self, key: str):\n",
      "        if key in self.reference.group.keys():\n",
      "            if key not in self.group.keys():\n",
      "                self.group.create_group(key)\n",
      "        return SharedAssay(\n",
      "            private_path=super()._get_item_impl(key).group_path,\n",
      "            public_path=self.reference[key].group_path,\n",
      "            ref=self.parent,\n",
      "            var_names=self.reference[key].var_names,\n",
      "            public_read_only=self.parent._public_read_only\n",
      "        )\n",
      "\n",
      "\n",
      "class SharedSubClusters(SubClusters):\n",
      "    def __init__(self, zarr_group: zarr.Group, parent, reference):\n",
      "        super().__init__(zarr_group, parent)\n",
      "        self.reference: SubClusters = reference\n",
      "\n",
      "    def __contains__(self, key):\n",
      "        if self.reference:\n",
      "            return super().__contains__(key) or self.reference.__contains__(key)\n",
      "        return super().__contains__(key)\n",
      "\n",
      "    def _get_item_impl(self, key: str):\n",
      "        if key in self.group:\n",
      "            return super()._get_item_impl(key)\n",
      "        if self.reference:\n",
      "            return self.reference[key]\n",
      "        raise KeyError(f\"Subcluster {key} not found in both private and reference data.\")\n",
      "\n",
      "    def keys(self):\n",
      "        # If the origin data haven't create subcluster yet, the reference will return None.\n",
      "        # See _init_attribute for more infomation.\n",
      "        if self.reference:\n",
      "            return set([*super().keys(), *self.reference.keys()])\n",
      "        return super().keys()\n",
      "\n",
      "\n",
      "class SharedAnnData(AppAnnData):\n",
      "    def __init__(\n",
      "        self,\n",
      "        private_path: str,\n",
      "        public_path: str,\n",
      "        public_read_only: bool = True,\n",
      "        standardize_path: Optional[str] = None,\n",
      "    ):\n",
      "        if not public_read_only:\n",
      "            group = zarr.group(public_path)\n",
      "        else:\n",
      "            group = zarr.Group(public_path, read_only=public_read_only)\n",
      "        super().__init__(group)\n",
      "        self.private = AppAnnData(zarr.open(private_path))\n",
      "        if standardize_path:\n",
      "            self.std = AppAnnData(zarr.open(standardize_path))\n",
      "            self.std._init_attribute(AnnDataAttr.OBS.value, AppObs)\n",
      "        else:\n",
      "            self.std = None\n",
      "\n",
      "        self._public_read_only = public_read_only\n",
      "\n",
      "    def _init_private_attribute(self, key: str):\n",
      "        if key not in self.private.group:\n",
      "            self.private.group.create_group(key)\n",
      "\n",
      "    def _init_shared_attribute(self, key: str, SharedAttribute, Attribute):\n",
      "        self._init_private_attribute(key)\n",
      "        return SharedAttribute(self.private.group[key], self, self._init_attribute(key, Attribute))\n",
      "\n",
      "    @cached_property\n",
      "    def obs(self) -> SharedObs:\n",
      "        if self.std:\n",
      "            self._init_private_attribute(AnnDataAttr.OBS.value)\n",
      "            return SharedObs(\n",
      "                zarr_group=self.private.group[AnnDataAttr.OBS.value],\n",
      "                parent=self,\n",
      "                reference=self._init_attribute(AnnDataAttr.OBS.value, AppObs),\n",
      "                std=self.std.obs,\n",
      "            )\n",
      "        return self._init_shared_attribute(AnnDataAttr.OBS.value, SharedObs, AppObs)\n",
      "\n",
      "    @cached_property\n",
      "    def obsm(self) -> SharedObsm:\n",
      "        return self._init_shared_attribute(AnnDataAttr.OBSM.value, SharedObsm, AppObsm)\n",
      "\n",
      "    @cached_property\n",
      "    def assays(self) -> SharedAssays:\n",
      "        return self._init_shared_attribute(AnnDataAttr.ASSAYS.value, SharedAssays, Assays)\n",
      "\n",
      "    @cached_property\n",
      "    def subclusters(self):\n",
      "        return self._init_shared_attribute(\n",
      "            AnnDataAttr.SUBCLUSTERS.value, SharedSubClusters, SubClusters\n",
      "        )\n",
      "\n",
      "    @cached_property\n",
      "    def uns(self) -> SharedUns:\n",
      "        return self._init_shared_attribute(AnnDataAttr.UNS.value, SharedUns, AppUns)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blob = mutual_base.tree[diff.a_path]\n",
    "content = blob.data_stream.read().decode('utf-8')\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34078892",
   "metadata": {},
   "source": [
    "# Try tree sitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92b99580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter_languages import get_language, get_parser\n",
    "\n",
    "language = get_language('python')\n",
    "parser = get_parser(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04e55b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tree_sitter.Tree object at 0x7b75ed211530>\n"
     ]
    }
   ],
   "source": [
    "tree = parser.parse(content.encode('utf-8'))\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a215cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -25,12 +25,11 @@ from bioalpha.store.anndata.shared import SharedObs, SharedUns, SharedObsm, Shar\n",
      " from bioalpha.constants import IOSpecs, AnnDataAttr, AnnDataAxis, AnnDataViewAttr\n",
      " from bioalpha.utils import (\n",
      "     validate_type,\n",
      "-    get_group_path,\n",
      "     is_group_readonly,\n",
      "     validate_subset_indices,\n",
      "     write_iospec,\n",
      " )\n",
      "-\n",
      "+from bioalpha.compat import get_group_path\n",
      " \n",
      " class BackedRaw:\n",
      "     \"\"\"Currently support read-only\"\"\"\n",
      "@@ -678,7 +677,7 @@ class SharedAssay(Assay):\n",
      "         if not public_read_only:\n",
      "             group = zarr.group(public_path)\n",
      "         else:\n",
      "-            group = zarr.Group(public_path, read_only=public_read_only)\n",
      "+            group = zarr.open_group(public_path, mode = \"r\")\n",
      "         super().__init__(group=group, ref=ref)\n",
      "         self.private = Assay(zarr.open(private_path), ref=ref)\n",
      "         if len(self.private.var_names) == 0:\n",
      "@@ -757,7 +756,7 @@ class SharedAnnData(AppAnnData):\n",
      "         if not public_read_only:\n",
      "             group = zarr.group(public_path)\n",
      "         else:\n",
      "-            group = zarr.Group(public_path, read_only=public_read_only)\n",
      "+            group = zarr.open_group(public_path, mode='r')\n",
      "         super().__init__(group)\n",
      "         self.private = AppAnnData(zarr.open(private_path))\n",
      "         if standardize_path:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(diff.diff.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acfd6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path_to_deepest_node_at_line(node, line):\n",
    "    if not (node.start_point[0] <= line <= node.end_point[0]):\n",
    "        return None\n",
    "\n",
    "    for child in node.children:\n",
    "        child_path = find_path_to_deepest_node_at_line(child, line)\n",
    "        if child_path:\n",
    "            return [node] + child_path\n",
    "\n",
    "    return [node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8642d88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Node type=import_from_statement, start_point=(0, 0), end_point=(0, 31)>,\n",
       " <Node type=import_statement, start_point=(2, 0), end_point=(2, 11)>,\n",
       " <Node type=import_statement, start_point=(3, 0), end_point=(3, 11)>,\n",
       " <Node type=import_statement, start_point=(4, 0), end_point=(4, 11)>,\n",
       " <Node type=import_statement, start_point=(5, 0), end_point=(5, 18)>,\n",
       " <Node type=import_statement, start_point=(6, 0), end_point=(6, 19)>,\n",
       " <Node type=import_from_statement, start_point=(7, 0), end_point=(7, 24)>,\n",
       " <Node type=import_from_statement, start_point=(8, 0), end_point=(8, 37)>,\n",
       " <Node type=import_from_statement, start_point=(9, 0), end_point=(9, 72)>,\n",
       " <Node type=import_from_statement, start_point=(11, 0), end_point=(11, 27)>,\n",
       " <Node type=import_from_statement, start_point=(12, 0), end_point=(12, 43)>,\n",
       " <Node type=import_from_statement, start_point=(13, 0), end_point=(13, 51)>,\n",
       " <Node type=import_from_statement, start_point=(15, 0), end_point=(15, 47)>,\n",
       " <Node type=import_from_statement, start_point=(16, 0), end_point=(16, 83)>,\n",
       " <Node type=import_from_statement, start_point=(17, 0), end_point=(17, 88)>,\n",
       " <Node type=import_from_statement, start_point=(18, 0), end_point=(21, 1)>,\n",
       " <Node type=import_from_statement, start_point=(22, 0), end_point=(22, 97)>,\n",
       " <Node type=import_from_statement, start_point=(24, 0), end_point=(24, 81)>,\n",
       " <Node type=import_from_statement, start_point=(25, 0), end_point=(31, 1)>,\n",
       " <Node type=class_definition, start_point=(34, 0), end_point=(88, 19)>,\n",
       " <Node type=class_definition, start_point=(91, 0), end_point=(94, 21)>,\n",
       " <Node type=class_definition, start_point=(97, 0), end_point=(343, 57)>,\n",
       " <Node type=class_definition, start_point=(346, 0), end_point=(389, 69)>,\n",
       " <Node type=class_definition, start_point=(392, 0), end_point=(467, 19)>,\n",
       " <Node type=class_definition, start_point=(470, 0), end_point=(508, 18)>,\n",
       " <Node type=class_definition, start_point=(511, 0), end_point=(587, 19)>,\n",
       " <Node type=class_definition, start_point=(590, 0), end_point=(631, 18)>,\n",
       " <Node type=function_definition, start_point=(634, 0), end_point=(665, 5)>,\n",
       " <Node type=class_definition, start_point=(668, 0), end_point=(698, 88)>,\n",
       " <Node type=class_definition, start_point=(701, 0), end_point=(720, 9)>,\n",
       " <Node type=class_definition, start_point=(723, 0), end_point=(745, 29)>,\n",
       " <Node type=class_definition, start_point=(748, 0), end_point=(806, 84)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.root_node.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45532c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Node type=import_from_statement, start_point=(13, 0), end_point=(13, 51)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.root_node.children[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49b848dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Node type=module, start_point=(0, 0), end_point=(807, 0)>,\n",
       " <Node type=class_definition, start_point=(34, 0), end_point=(88, 19)>,\n",
       " <Node type=block, start_point=(35, 4), end_point=(88, 19)>,\n",
       " <Node type=decorated_definition, start_point=(58, 4), end_point=(61, 27)>,\n",
       " <Node type=function_definition, start_point=(59, 4), end_point=(61, 27)>,\n",
       " <Node type=block, start_point=(60, 8), end_point=(61, 27)>,\n",
       " <Node type=expression_statement, start_point=(60, 8), end_point=(60, 63)>,\n",
       " <Node type=call, start_point=(60, 8), end_point=(60, 63)>,\n",
       " <Node type=identifier, start_point=(60, 8), end_point=(60, 21)>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = find_path_to_deepest_node_at_line(tree.root_node, 60)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7a27797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'module'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.root_node.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ef909",
   "metadata": {},
   "source": [
    "# Call Diff Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85931160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.diff.diff_analysis import DiffAnalyzer\n",
    "\n",
    "diff_analysier = DiffAnalyzer(\"/home/haianhlt/Documents/bioturing/bioalpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47c5e9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 17:29:20,555 - DEBUG - sys.platform='linux', git_executable='git'\n",
      "2026-02-02 17:29:20,558 - DEBUG - Popen(['git', 'cat-file', '--batch-check'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=<valid stream>, shell=False, universal_newlines=False)\n",
      "2026-02-02 17:29:20,563 - DEBUG - Popen(['git', 'merge-base', '36223441c04ac7033262998187508e1069c42733', '3e9fa5f0137544480673546b5ee1335d242abe7e'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=None, shell=False, universal_newlines=False)\n",
      "2026-02-02 17:29:20,570 - DEBUG - Popen(['git', 'diff-tree', '3e9fa5f0137544480673546b5ee1335d242abe7e', '36223441c04ac7033262998187508e1069c42733', '-r', '--abbrev=40', '--full-index', '-M', '--raw', '-z', '--no-color'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=None, shell=False, universal_newlines=False)\n",
      "2026-02-02 17:29:20,585 - DEBUG - Popen(['git', 'diff-tree', '3e9fa5f0137544480673546b5ee1335d242abe7e', '36223441c04ac7033262998187508e1069c42733', '-r', '--abbrev=40', '--full-index', '-M', '-p', '--no-ext-diff', '--no-color'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=None, shell=False, universal_newlines=False)\n",
      "2026-02-02 17:29:20,610 - DEBUG - Popen(['git', 'cat-file', '--batch'], cwd=/home/haianhlt/Documents/bioturing/bioalpha, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<src.diff.diff_analysis.KudoDiff at 0x7b75cbce7850>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75ed0ee5d0>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb34c10>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbd24350>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb2d610>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbd13f90>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbd13990>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbcf2d90>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75edafd290>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb58250>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb5a750>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb58a90>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb5a790>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb5a510>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbcfad50>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbd11750>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb57c50>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbd12610>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb2e850>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbb362d0>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75ed10aad0>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c65fe610>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c65fee50>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c6534f10>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75edb25910>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c65b6b90>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75edb49a90>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c653b490>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c653b390>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c65be410>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c65bca90>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75ed10ab50>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c65bfb90>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c658b450>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c64009d0>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c6400890>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75cbd24550>,\n",
       " <src.diff.diff_analysis.KudoDiff at 0x7b75c65ea9d0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs = diff_analysier.analyze_diffs(\"tk726_zarr3\", \"main\")\n",
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dcf714d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.semantic_ast.ast_file_analysis.SemanticASTNode at 0x7b75cbb50590>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sast = diffs[2].semantic_ast.root\n",
    "sast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3664121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Node type=import_statement, start_point=(0, 0), end_point=(0, 9)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sast.children[0].ast_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4a716fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== src/bioalpha/store/dataframe.py === \n",
      "<Node type=module, start_point=(0, 0), end_point=(405, 0)>\n",
      ".....\n",
      "from abc import ABC, abstractmethod\n",
      ".....\n",
      "class OneDim(ABC):\n",
      "    \"\"\"\n",
      "    Validation helper mapping keys to one-dimensional array-like structures\n",
      "    aligned with an axis of the parent AnnData-like object.\n",
      "    This is compatible with AnnData `obs` and `var`.\n",
      "    \"\"\"\n",
      "\n",
      "    _parent: Any\n",
      "\n",
      "    def __init__(self, parent: Any):\n",
      "        self._parent = parent\n",
      "\n",
      "    @property\n",
      "    def parent(self):\n",
      "        return self._parent\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def axis(self) -> int:\n",
      "        \"\"\"Indicates the axis being represented (0 for `obs`, 1 for `var`).\"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    def _get_index_impl(self) -> object:\n",
      "        \"\"\"Retrieves index of the object.\"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    def _set_index_impl(self, index: Iterator[Union[str, np.number]]):\n",
      "        \"\"\"Sets index of the object.\"\"\"\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def dtypes(self) -> pd.Series:\n",
      "        \"\"\"Returns the data types of the elements, similar to pandas.DataFrame.dtypes.\"\"\"\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def columns(self) -> List[str]:\n",
      "        \"\"\"Returns the names of the columns, similar to pandas.DataFrame.columns.\"\"\"\n",
      "\n",
      "    @property\n",
      "    def index(self) -> Iterator[Union[str, np.number]]:\n",
      "        \"\"\"Returns the index of the obs or var.\"\"\"\n",
      "        return self._get_index_impl()\n",
      "\n",
      "    @index.setter\n",
      "    def index(self, index: Iterator[Union[str, np.number]]):\n",
      "        \"\"\"Sets a new index for the obs or var.\"\"\"\n",
      "        if self.parent.shape[self.axis]:\n",
      "            assert len(index) == self.parent.shape[self.axis]\n",
      "        return self._set_index_impl(index)\n",
      "\n",
      "    @abstractmethod\n",
      "    def __len__(self) -> int:\n",
      "        pass\n",
      "\n",
      "    def _validate_value(self, values):\n",
      "        if len(values) != len(self):\n",
      "            raise ValueError(\n",
      "                f\"Length of values ({len(values)}) \"\n",
      "                f\"does not match length of index ({len(self)})\"\n",
      "            )\n",
      "        if isinstance(values, np.ndarray):\n",
      "            if values.ndim > 1:\n",
      "                raise ValueError(\n",
      "                    f\"Expected a 1D array, got an array with shape {values.shape}\"\n",
      "                )\n",
      "\n",
      "    # The AxisArraysBase.to_df is too slow and required a lot of memory.\n",
      "    def to_df(self) -> pd.DataFrame:\n",
      "        \"\"\"Convert to pandas DataFrame\"\"\"\n",
      "        keys = self.columns\n",
      "        if keys:\n",
      "            return pd.DataFrame({key: self[key] for key in keys}, index=self.index)\n",
      "        return pd.DataFrame(index=self.index)\n",
      "\n",
      "    def copy(self):\n",
      "        return self.to_df().copy()\n",
      "\n",
      "    @property\n",
      "    def dim_names(self) -> pd.Index:\n",
      "        return self.index\n",
      ".....\n",
      "class BackedDataFrame(ABC):\n",
      "    _index_key: str\n",
      "\n",
      "    def __init__(self, group: Union[zarr.Group, h5py.Group]) -> None:\n",
      "        self._group = group\n",
      "        if not is_group_readonly(group):\n",
      "            write_iospec(IOSpecs.DATAFRAME.value, group, overwrite=False)\n",
      "        self._index_key = group.attrs.get(\n",
      "            DataFrameAttr.INDEX_KEY.value, DataFrameAttr.INDEX_KEY.value)\n",
      "\n",
      "    @property\n",
      "    def group(self) -> Union[zarr.Group, h5py.Group]:\n",
      "        return self._group\n",
      "\n",
      "    @property\n",
      "    def columns(self) -> List[str]:\n",
      "        return [col for col in self.keys() if col != self._index_key]\n",
      "\n",
      "    @property\n",
      "    def dtypes(self) -> pd.Series:\n",
      "        dtypes = {}\n",
      "        for key in self.columns:\n",
      "            try:\n",
      "                group_key = self.group[key]\n",
      "            except Exception:\n",
      "                group_key = self.group[self._name2id[key]]\n",
      "            arr_type = dict(group_key.attrs).get(IOSpecsAttr.ENCODING_TYPE.value, \"array\")\n",
      "            dtypes[key] = (\n",
      "                np.dtype(\"float32\") if arr_type == \"array\"\n",
      "                else pd.CategoricalDtype(categories=group_key[\"categories\"])\n",
      "            )\n",
      "        return pd.Series(dtypes)\n",
      "\n",
      "    def _validate_key(self, key: str):\n",
      "        if key == self._index_key:\n",
      "            raise KeyError(f\"Unable to manipulate index: `{self._index_key}`\")\n",
      "        if \"/\" in key:\n",
      "            raise ValueError(\n",
      "                \"Key should not contain '/', it will break when store in .hdf5 or .zarr file.\")\n",
      "\n",
      "    def _get_item_impl(self, key: Union[str, List[str]]) -> pd.Series:\n",
      "        if isinstance(key, list):\n",
      "            return pd.DataFrame({k: self[k] for k in key}, index=self.index)\n",
      "\n",
      "        element = self.group[key]\n",
      "\n",
      "        # deprecated\n",
      "        if element.attrs.get(\"metadata_type\", \"\") == \"category\":\n",
      "            catagory_names = element.attrs[\"category_names\"]\n",
      "            return pd.Series(np.array(catagory_names)[element[:]], name=key, index=self.index)\n",
      "\n",
      "        return pd.Series(read_elem(element), name=key, index=self.index)\n",
      "\n",
      "    def _set_item_impl(self, key: str, values: Union[pd.Series, pd.Categorical, np.ndarray]):\n",
      "        if key == self._index_key:\n",
      "            raise KeyError(f\"Unable to manipulate index: `{self._index_key}`\")\n",
      "        write_elem(self.group, key, convert_df_series(values))\n",
      "\n",
      "    def _del_item_impl(self, key: str):\n",
      "        if key == self._index_key:\n",
      "            raise KeyError(f\"Unable to delete index: `{self._index_key}`\")\n",
      "        if len(key) == 0:\n",
      "            raise KeyError(\"Unable to delete item with the empty key.\")\n",
      "        if key in self.group:\n",
      "            del self.group[key]\n",
      "\n",
      "    def _get_index_impl(self) -> pd.Series:\n",
      "        if self._index_key not in self.group:\n",
      "            return []\n",
      "        return pd.Series(read_elem(self.group[self._index_key]), name=self._index_key)\n",
      "\n",
      "    def _set_index_impl(self, index: Iterator[Union[str, np.number]]):\n",
      "        index = pd.Series(index)\n",
      "        if self._index_key in self.group:\n",
      "            raise KeyError(f\"Index already exists: {self._index_key}\")\n",
      "        write_elem(self.group, self._index_key, index.values)\n",
      "\n",
      "    def __len__(self):\n",
      "        if self._index_key not in self.group:\n",
      "            return 0\n",
      "        return len(self.group[self._index_key])\n",
      ".....\n",
      "class DataFrameView:\n",
      "    _parent: Any\n",
      "\n",
      "    def __init__(self, ref: BackedDataFrame, parent: Any) -> None:\n",
      "        self.ref = ref\n",
      "        self._parent = parent\n",
      "\n",
      "    @property\n",
      "    def parent(self) -> Any:\n",
      "        return self._parent\n",
      "\n",
      "    @property\n",
      "    def ref(self) -> BackedDataFrame:\n",
      "        return self._ref\n",
      "\n",
      "    @ref.setter\n",
      "    def ref(self, ref: BackedDataFrame):\n",
      "        validate_type(ref, BackedDataFrame)\n",
      "        self._ref = ref\n",
      "\n",
      "    @property\n",
      "    def axis(self) -> int:\n",
      "        return self.ref.axis\n",
      "\n",
      "    def keys(self) -> List[str]:\n",
      "        return self.ref.keys()\n",
      "\n",
      "    @property\n",
      "    def columns(self) -> List[str]:\n",
      "        return self.ref.columns\n",
      "\n",
      "    @property\n",
      "    def dtypes(self) -> pd.Series:\n",
      "        return self.ref.dtypes\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        return self.parent.shape[self.axis]\n",
      "\n",
      "    def __getitem__(self, key) -> pd.Series:\n",
      "        indices = self.parent.indices[self.axis]\n",
      "        if indices is None:\n",
      "            return self.ref[key]\n",
      "        return self.ref[key].iloc[indices]\n",
      "\n",
      "    @property\n",
      "    def index(self) -> Iterator[Union[str, np.number]]:\n",
      "        ref_index = self.ref.index\n",
      "        if self.parent.indices[self.axis] is None:\n",
      "            return ref_index\n",
      "        return ref_index.iloc[self.parent.indices[self.axis]]\n",
      "\n",
      "    def to_df(self) -> pd.DataFrame:\n",
      "        \"\"\"Convert to pandas DataFrame\"\"\"\n",
      "        keys = [key for key in self.keys() if key != DataFrameAttr.INDEX_KEY.value]\n",
      "        if keys:\n",
      "            return pd.concat([self[key] for key in keys], axis=1, keys=keys)\n",
      "        return pd.DataFrame(index=self.index)\n",
      "\n",
      "    def copy(self):\n",
      "        return self.to_df().copy()\n",
      "\n",
      "    def __iter__(self):\n",
      "        yield from self.columns\n",
      "\n",
      "    def read_attrs(self, key: str):\n",
      "        return self.ref.read_attrs(key)\n",
      "\n",
      "    @property\n",
      "    def is_view(self):\n",
      "        return True\n",
      "\n",
      "    @property\n",
      "    def dim_names(self) -> pd.Index:\n",
      "        return self.index\n",
      "\n",
      "    def get_id_by_name(self, name):\n",
      "        return self.ref.get_id_by_name(name)\n",
      ".....\n",
      "class AppObs(BackedDataFrame, OneDim, AppCollection):\n",
      "    def __init__(self, group: Union[zarr.Group, h5py.Group], parent):\n",
      "        BackedDataFrame.__init__(self, group)\n",
      "        OneDim.__init__(self, parent)\n",
      "\n",
      "    @property\n",
      "    def axis(self):\n",
      "        return AnnDataAxis.OBS.value\n",
      "\n",
      "    @cached_property\n",
      "    def z_metadata_group(self) -> Union[Attributes, Dict[str, Dict[str, str]]]:\n",
      "        return Attributes(\n",
      "            self.group.store,\n",
      "            key=os.path.join(self.group_path, MetadataGroup.FILE_NAME.value)\n",
      "        )\n",
      "\n",
      "    # overload AppCollection.__setitem__() to automatically save changed metadata id\n",
      "    def __setitem__(self, key, value):\n",
      "        old_id = self.get_id_by_name(key)\n",
      "        AppCollection.__setitem__(self, key, value)\n",
      "        new_id = self.get_id_by_name(key)\n",
      "\n",
      "        if old_id in self.z_metadata_group.get(MetadataGroup.MAPPING.value, {}) and old_id != new_id:\n",
      "            self._update_metadata_group(\n",
      "                MetadataGroup.MAPPING.value,\n",
      "                new_id,\n",
      "                self._pop_metadata_group(MetadataGroup.MAPPING.value, old_id)\n",
      "            )\n",
      "\n",
      "    def _update_metadata_group(self, field: str, key: str, value: str):\n",
      "        if field not in [MetadataGroup.MAPPING.value, MetadataGroup.GROUPS.value]:\n",
      "            raise KeyError(f\"Key {field} is not supported in metadata groups.\")\n",
      "        tmp = self.z_metadata_group.get(field, {})\n",
      "        tmp[key] = value\n",
      "        self.z_metadata_group[field] = tmp\n",
      "\n",
      "    def _pop_metadata_group(self, field: str, key: str):\n",
      "        if field not in [MetadataGroup.MAPPING.value, MetadataGroup.GROUPS.value]:\n",
      "            raise KeyError(f\"Key {field} is not supported in metadata groups.\")\n",
      "        tmp = self.z_metadata_group.get(field, {})\n",
      "        ret = tmp.pop(key)\n",
      "        self.z_metadata_group[field] = tmp\n",
      "        return ret\n",
      "\n",
      "    def create_metadata_group(self, name: str):\n",
      "        if name in self.z_metadata_group.get(MetadataGroup.GROUPS.value, {}):\n",
      "            raise KeyError(f\"Metadata group {name} already exists.\")\n",
      "\n",
      "        self._update_metadata_group(MetadataGroup.GROUPS.value, name, self.generate_elem_id())\n",
      "        return self.z_metadata_group.asdict()\n",
      "\n",
      "    def rename_metadata_group(self, old_name: str, new_name: str):\n",
      "        if old_name not in self.z_metadata_group.get(MetadataGroup.GROUPS.value, {}):\n",
      "            raise KeyError(f\"Metadata group {old_name} does not exist.\")\n",
      "        if new_name in self.z_metadata_group.get(MetadataGroup.GROUPS.value, {}):\n",
      "            raise KeyError(f\"Metadata group {new_name} already exists.\")\n",
      "\n",
      "        self._update_metadata_group(\n",
      "            MetadataGroup.GROUPS.value,\n",
      "            new_name,\n",
      "            self._pop_metadata_group(MetadataGroup.GROUPS.value, old_name)\n",
      "        )\n",
      "        return self.z_metadata_group.asdict()\n",
      "\n",
      "    def delete_metadata_group(self, group: str):\n",
      "        if group not in self.z_metadata_group.get(MetadataGroup.GROUPS.value, {}):\n",
      "            raise KeyError(f\"Metadata group {group} does not exist.\")\n",
      "\n",
      "        self._group_id_2_name = {\n",
      "            uuid: name\n",
      "            for name, uuid in self.z_metadata_group[MetadataGroup.GROUPS.value].items()\n",
      "        }\n",
      "        for m_uuid, g_uuid in list(self.z_metadata_group.get(MetadataGroup.MAPPING.value, {}).items()):\n",
      "            if self._group_id_2_name[g_uuid] == group:\n",
      "                self._pop_metadata_group(MetadataGroup.MAPPING.value, m_uuid)\n",
      "\n",
      "        self._pop_metadata_group(MetadataGroup.GROUPS.value, group)\n",
      "        return self.z_metadata_group.asdict()\n",
      "\n",
      "    def delete_metadata_from_current_group(self, metadata: str):\n",
      "        self._pop_metadata_group(MetadataGroup.MAPPING.value, self._name2id[metadata])\n",
      "        return self.z_metadata_group.asdict()\n",
      "\n",
      "    def change_metadata_group(self, group: str, metadata: str):\n",
      "        if group not in self.z_metadata_group.get(MetadataGroup.GROUPS.value, {}):\n",
      "            raise KeyError(f\"Metadata group {group} does not exists.\")\n",
      "\n",
      "        self._update_metadata_group(\n",
      "            MetadataGroup.MAPPING.value,\n",
      "            self._name2id[metadata],\n",
      "            self.z_metadata_group[MetadataGroup.GROUPS.value][group],\n",
      "        )\n",
      "        return self.z_metadata_group.asdict()\n",
      "\n",
      "    def change_multiple_metadata_group(self, groups: Union[str, List[str]], metadatas: List[str]):\n",
      "        if isinstance(groups, list):\n",
      "            if len(groups) != len(metadatas):\n",
      "                raise KeyError(f\"Length of group and metadata must be the same.\")\n",
      "        else:\n",
      "            groups = [groups] * len(metadatas)\n",
      "\n",
      "        for g, m in zip(groups, metadatas):\n",
      "            self.change_metadata_group(g, m)\n",
      "\n",
      "        return self.z_metadata_group.asdict()\n",
      "\n",
      "    def delete_multiple_metadata_from_groups(self, metadatas: List[str]):\n",
      "        for m in metadatas:\n",
      "            self._pop_metadata_group(MetadataGroup.MAPPING.value, self._name2id[m])\n",
      "\n",
      "        return self.z_metadata_group.asdict()\n",
      ".....\n"
     ]
    }
   ],
   "source": [
    "print(diffs[7].get_source_code_context())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c474eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ -25,12 +25,11 @@ from bioalpha.store.anndata.shared import SharedObs, SharedUns, SharedObsm, Shar\n",
      " from bioalpha.constants import IOSpecs, AnnDataAttr, AnnDataAxis, AnnDataViewAttr\n",
      " from bioalpha.utils import (\n",
      "     validate_type,\n",
      "-    get_group_path,\n",
      "     is_group_readonly,\n",
      "     validate_subset_indices,\n",
      "     write_iospec,\n",
      " )\n",
      "-\n",
      "+from bioalpha.compat import get_group_path\n",
      " \n",
      " class BackedRaw:\n",
      "     \"\"\"Currently support read-only\"\"\"\n",
      "@@ -678,7 +677,7 @@ class SharedAssay(Assay):\n",
      "         if not public_read_only:\n",
      "             group = zarr.group(public_path)\n",
      "         else:\n",
      "-            group = zarr.Group(public_path, read_only=public_read_only)\n",
      "+            group = zarr.open_group(public_path, mode = \"r\")\n",
      "         super().__init__(group=group, ref=ref)\n",
      "         self.private = Assay(zarr.open(private_path), ref=ref)\n",
      "         if len(self.private.var_names) == 0:\n",
      "@@ -757,7 +756,7 @@ class SharedAnnData(AppAnnData):\n",
      "         if not public_read_only:\n",
      "             group = zarr.group(public_path)\n",
      "         else:\n",
      "-            group = zarr.Group(public_path, read_only=public_read_only)\n",
      "+            group = zarr.open_group(public_path, mode='r')\n",
      "         super().__init__(group)\n",
      "         self.private = AppAnnData(zarr.open(private_path))\n",
      "         if standardize_path:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(diffs[5].diff_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83cab49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Node type=module, start_point=(0, 0), end_point=(807, 0)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_tree = diffs[5].semantic_ast.root\n",
    "check_tree.ast_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5dea845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_tree.children[1].children"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kudo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
